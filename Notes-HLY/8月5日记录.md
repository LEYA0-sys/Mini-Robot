# 场景demo

**定时任务编排器**
每天凌晨1点自动分析并总结，生成最终播报文件，默认用于当天的用户。

**流程：**COS桶下载日志->三类Agent并发数据分析+对分析结论进行向量化->向量化的文件移交给阿里的千问模型进行总结->得到一个总结三类日志的总结文件->保存在指定路径下

**MCP Tool 1：快速播报**  
用户说“开始播报”时，MCP tool 直接读取当天的总结文件并播报，无需等待分析流程。

**MCP Tool 2：重新分析并播报**  
如果当天用户和前一天不同，用户给出指令，然后调用编排器全流程，分析完成后再播报。



# 已实现

## 编排器

/home/ubuntu/prjs/xiaozhi-esp32-server/main/xiaozhi-server/plugins_func/functions/log_analysis_orchestrator.py

/home/ubuntu/prjs/xiaozhi-esp32-server/main/xiaozhi-server/plugins_func/functions/schedule_log_analysis.py

1. 修复了循环导入问题：
   - 将 `log_analysis_orchestrator` 的导入移到函数内部
   - 添加了项目根目录到 Python 路径

2. 服务状态：
   - 服务已经成功启动并运行
   - 日志显示初始化成功
   - 设置为开机自启动

3. 定时任务设置：
   - 每天凌晨1点自动运行
   - 会分析前一天的所有日志类型
   - 包含失败重试机制

您现在可以通过以下命令来管理服务：
- `sudo systemctl status log-analysis-scheduler` - 查看服务状态
- `sudo systemctl restart log-analysis-scheduler` - 重启服务
- `sudo systemctl stop log-analysis-scheduler` - 停止服务
- `sudo journalctl -u log-analysis-scheduler` - 查看服务日志
- `systemctl enable` - 设置服务在系统启动时自动启动
- `systemctl disable` - 取消服务的开机自启动

![image-20250805230417757](./8%E6%9C%885%E6%97%A5%E8%AE%B0%E5%BD%95.assets/image-20250805230417757-1754406258660-1.png)

## MCP

2个MCP工具已经实现但是没有测试



# 待实现

1.测试编排器功能并且调试(7号-9号)

![66f7d8cf13d8a103e4a44bf18766542c](./8%E6%9C%885%E6%97%A5%E8%AE%B0%E5%BD%95.assets/66f7d8cf13d8a103e4a44bf18766542c-1754480764105-2.png)



2.实现第一个场景demo，也就是机器人播报好日志以后，用户给出回滚指令，需要对哪类日志里面的错误信息进行回滚

3.讨论回滚情景，先实现一条链路，业务日志为出发点分析其他两类日志，比如用户说出“开始分析业务日志”就开始对三类日志进行分析并回滚

目前思路：

写MCP，用于进行业务日志为出发点的回滚

回滚过程需要进行溯源，从业务、事件、审计日志进行检索分析得出修复建议

播报修复建议，得到用户同意->开始进行自动调用工具进行回滚



# 计划

7-9号：测试并调试编排器 + 测试新方案

10号-14号：编写业务日志出发的MCP工具，涉及日志之间互相检索、分析得到解决方案，如果提前成功就写从事件、审计日志出发的MCP

15号-23号：根据解决方法进行回滚

7-15号期间8号参加例会